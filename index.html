<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=840, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="author" content="Ziru Chen" />
    <meta name="description" content="Homepage" />

    <link rel="shortcut icon" type="image/jpg" href="img/R_favicon.jpg" />
    <title>Ziru Chen - The Ohio State University</title>

    <!-- Bootstrap core CSS -->
    <link href="bootstrap/css/bootstrap.css" rel="stylesheet" />
    <!-- Custom styles for this template -->
    <link href="theme.css" rel="stylesheet" />
    <!-- Pretty icons from https://feathericons.com/ -->
  </head>

  <body>
    <!--
    <div class="container">
      <ul class="nav nav-pills nav-fill justify-content-center">
        <li class="nav-item">
          <a class="nav-link active" href="index.html">Z. Chen</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="file/Chen_Ziru.pdf">C.V.</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="pub.html">Research</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="pub.html">Publications</a>
        </li>
      </ul>
    </div>
    -->

    <div class="container">
      <div id="container-home">
        <div class="title">
          <div class="intro">
            <br />
            <div class="photo"><img src="img/photo.jpg" /></div>
          </div>
          <h3><strong>Ziru Chen</strong></h3>
          Ron | 陈子如 | チン シジョ <br />
          <a href="https://www.osu.edu/"
            ><strong>The Ohio State University</strong></a
          >
          <br />
          <embed
            src="img/file-text.svg"
            width="16"
            height="16"
            type="image/svg+xml"
          />
          <a href="file/Chen_Ziru_CV.pdf">C.V.</a>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <embed
            src="img/mail.svg"
            width="16"
            height="16"
            type="image/svg+xml"
          />
          <a href="mailto:chen.8336@osu.edu">chen.8336@osu.edu</a> <br />
          <embed
            src="img/github.svg"
            width="16"
            height="16"
            type="image/svg+xml"
          />
          <a href="https://github.com/ronch99">ronch99</a>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <embed
            src="img/twitter.svg"
            width="16"
            height="16"
            type="image/svg+xml"
          />
          <a href="https://twitter.com/RonZiruChen">@RonZiruChen</a> <br />
          <br />

          I am a Ph.D. student advised by Dr.
          <a href="https://u.osu.edu/ihudas/people/">Huan Sun</a>. My research
          focuses on <i>Conversational AI Agents</i>,
          <i>Natural Language Processing</i>, and <i>Machine Learning</i>, with
          an emphasis on the following two areas:<br />
          <ul>
            <li>
              <strong>Post-training and Test-Time Computation of LLMs</strong>:
              While large language models (LLMs) have demonstrated great
              success, one concensus between theoretical and empirical research
              is that they need enough test-time computation to perform complex
              reasoning and planning. With chain-of-thought
              <a href="https://arxiv.org/abs/2305.14215">[EMNLP'23]</a> or
              program-of-thought
              <a href="https://arxiv.org/abs/2305.13073">[ACL'23]</a>, LLMs can
              effectively extend their "thinking" to solve more challenging
              tasks and even win gold medals in international olympiads
              <a href="https://arxiv.org/abs/2510.05016">[Arxiv'25a]</a>. Before
              reinforcement learning with verifiable rewards (RLVR) becomes a
              prevalent paradigm, my research has already highlighted
              verification as a key factor in scaling LLMs' test-time
              computation
              <a href="https://arxiv.org/abs/2402.10890">[ACL'24]</a>, including
              parallel scaling (e.g., sampling) and recurrent scaling (e.g.,
              searching). With recent advances in RLVR, I am exploring new
              post-training methods to further enhance LLMs' test-time
              computation capabilities toward self-evolving AI models.
            </li>
            <li>
              <strong>Language Agents for Coding and Data Analysis</strong>: I
              have been developing task-oriented conversational AI systems
              <a href="https://arxiv.org/abs/2207.05223">[AlexaPrize'22]</a>
              before the advent of LLMs and language agents. I am particularly
              interested in building language agents that can perform complex
              coding and data analysis tasks in real-world scenarios, such as
              database management
              <a href="https://arxiv.org/abs/2305.13073">[ACL'23]</a
              ><a href="https://arxiv.org/abs/2305.14215">[EMNLP'23]</a> and
              scientific discovery
              <a href="https://arxiv.org/abs/2410.05080">[ICLR'25]</a>
              <a href="https://arxiv.org/abs/2506.08140">[EMNLP'25]</a>.
              Currently, I am actively thinking about three future directions of
              language agent research: (1) rigorous and holistic evaluation of
              agents in ecologically valid settings
              <a href="https://arxiv.org/abs/2510.11977">[Arxiv'25b]</a>; (2)
              principled and cost-efficient agent scaffold designs for data
              synthesis and model training <a href="#">[Arxiv'25c]</a>; and (3)
              continual learning and adaptation in dynamic, user-involved
              environments.
            </li>
          </ul>
          <!--
          <br />
          <embed
            src="img/calendar.svg"
            width="16"
            height="16"
            type="image/svg+xml"
          />
          07/09 - 14: <strong>Attending ACL 2023 in person</strong>
          <br />
          -->
        </div>

        <div class="news">
          <h4 id="News">
            <strong><i>News</i></strong>
          </h4>
          <div id="newslist">
            <!--
            <embed
              src="img/calendar.svg"
              width="16"
              height="16"
              type="image/svg+xml"
            />
            Currently, attending
            <a href="https://www.amazon.science/alexa-prize/taskbot-challenge"
              >Alexa Prize TaskBot Challege</a
            >
            as an internal lead of
            <a
              href="https://cse.osu.edu/news/2021/06/osu-team-selected-participate-first-alexa-prize-taskbot-challenge"
              >Team Taco</a
            >! <br />
            <br />
            -->
            <ul>
              <li>
                10/2025: Three new preprints on agent evaluation and training:
                <a href="https://arxiv.org/abs/2510.11977"
                  >Holistic Agent Leaderboard</a
                >, <a href="https://arxiv.org/abs/2510.05016">LLMs at IOAA</a>,
                and <a href="#">Agent Data Protocol</a>.
              </li>
              <li>
                09/2025: Two follow-up papers on ScienceAgentBench:
                <a href="https://arxiv.org/abs/2506.08140">AutoSDT</a> is
                accepted at EMNLP 2025;
                <a href="https://arxiv.org/abs/2509.05881">GeoAnalystBench</a>
                is accepted at TGIS 2025.
              </li>
              <li>
                01/2025:
                <a href="https://osu-nlp-group.github.io/ScienceAgentBench/"
                  >ScienceAgentBench</a
                >
                is accepted at ICLR 2025; 1 paper on Chemistry agent accepted at
                NAACL 2025 (Findings).
              </li>
              <li>
                10/2024: Releasing
                <a href="https://osu-nlp-group.github.io/ScienceAgentBench/"
                  >ScienceAgentBench</a
                >, a new benchmark to rigorously assess language agents for
                data-driven scientific discovery. Check out our
                <a href="https://arxiv.org/abs/2410.05080"> pre-print</a> for
                more details.
              </li>
              <li>
                05/2024: 1 paper on planning with LLMs accepted at ACL 2024; 1
                paper on LLM for E-commerce and RecSys accepted at ICML 2024.
              </li>
              <li>
                10/2023: 2 papers on text-to-SQL parsing and 1 paper on LLM
                attribution evaluation accepted at EMNLP 2023.
              </li>
              <li>
                07/2023: Our
                <a href="https://sunlab-osu.github.io/tacobot/">TacoBot</a>
                report is accepted as a demo paper at SIGDIAL 2023.
              </li>
              <li>
                05/2023: 1 paper accepted at ACL 2023 and 3 preprints out on
                Arxiv.
              </li>
              <li>
                06/2022: Won the 3rd place in
                <a
                  href="https://www.amazon.science/alexa-prize/three-top-performers-emerge-in-inaugural-alexa-prize-taskbot-challenge"
                  >Alexa Prize TaskBot Challege</a
                >
                as a student co-lead! Check out our
                <a
                  href="https://www.amazon.science/alexa-prize/proceedings/bootstrapping-a-user-centered-task-oriented-dialogue-system"
                  >report</a
                >.
              </li>
              <li>
                04/2022: Excited to receive the
                <strong>Undergraduate Research Award</strong> from OSU CSE
                Department!
              </li>
              <li>
                02/2022: Thrilled to receive the
                <a
                  href="https://gradsch.osu.edu/pursuing-your-degree/graduate-fellows/university-fellowship"
                  >University Fellowship</a
                >
                as an incoming Ph.D. student!
              </li>
              <li>
                05/2021 - 07/2021: Had some fun time at Deep Learning Lab,
                <a href="https://en.westlake.edu.cn/">Westlake University</a> as
                a Research Intern.
              </li>
              <li>
                04/2021: Excited to receive the
                <strong>CIS Undrgrad Scholarship</strong> from OSU CSE
                Department!
              </li>
            </ul>
          </div>
        </div>

        <div class="awards">
          <h4 id="Awards">
            <strong><i>Honors and Awards</i></strong>
          </h4>
          <ul>
            <li>
              University Fellowship, The Ohio State University, 2022 - 2023 &
              2026 - 2027
            </li>
            <li>
              3rd Place (Student Co-lead of
              <a href="https://sunlab-osu.github.io/tacobot/">Team TacoBot</a>),
              1st Alexa Prize Taskbot Challenge, Amazon, 2022
            </li>
            <li>
              Undergraduate Research Award, The Ohio State University, 2022
            </li>
            <li>
              CIS Undergrad Scholarship, The Ohio State University, 2021 - 2022
            </li>
          </ul>
        </div>

        <div class="teaching">
          <h4 id="Teaching">
            <strong><i>Teaching</i></strong>
          </h4>
          <ul>
            <li>
              <a href="http://ronch99.github.io"
                ><i>CSE 5525 Speech and Language Processing</i></a
              >, Undergrad & Grad level<br />
              Teaching Assistant (Autumn 21, Spring 22)
            </li>
            <li>
              <a
                href="http://coe-portal.cse.ohio-state.edu/pdf-exports/CSE/CSE-2321.pdf"
                ><i>CSE 2321 Foundations I: Discrete Structures</i></a
              >, Undergrad level<br />
              Teaching Assistant (Autumn 19, Spring 20, Autumn 20)
            </li>
          </ul>
        </div>

        <div class="research">
          <br />
          <h4 id="Research">
            <strong><i>Selected Publications</i></strong>
          </h4>
          Please check out my
          <a href="https://scholar.google.com/citations?user=1-pt7zMAAAAJ&hl=en"
            >Google Scholar</a
          >
          for a complete list of publications.
          <br /><br />
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2510.11977">
                <i
                  >Holistic Agent Leaderboard: The Missing Infrastructure for AI
                  Agent Evaluation</i
                >
              </a>
              <br />
              Sayash Kapoor, Benedikt Stroebl, Peter Kirgis, Nitya Nadgir,
              Zachary S Siegel, Boyi Wei, Tianci Xue,
              <strong>Ziru Chen</strong>, Felix Chen, Saiteja Utpala, Franck
              Ndzomga, Dheeraj Oruganty, Sophie Luskin, Kangheng Liu, Botao Yu,
              Amit Arora, Dongyoon Hahm, Harsh Trivedi, Huan Sun, Juyong Lee,
              Tengjun Jin, Yifan Mai, Yifei Zhou, Yuxuan Zhu, Rishi Bommasani,
              Daniel Kang, Dawn Song, Peter Henderson, Yu Su, Percy Liang,
              Arvind Narayanan <br />
              Arxiv Preprint (Arxiv 2025, Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2510.05016">
                <i
                  >Large Language Models Achieve Gold Medal Performance at the
                  International Olympiad on Astronomy & Astrophysics (IOAA)</i
                >
              </a>
              <br />
              Lucas Carrit Delgado Pinheiro*, <strong>Ziru Chen</strong>*, Bruno
              Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan
              Sun (* equal contribution) <br />
              Arxiv Preprint (Arxiv 2025, Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="#">
                <i
                  >Agent Data Protocol: Unifying Datasets for Diverse, Effective
                  Fine-tuning of LLM Agents</i
                >
              </a>
              <br />
              Yueqi Song, Ketan Ramaneti, Zaid Sheikh,
              <strong>Ziru Chen</strong>, Boyu Gou, Tianbao Xie, Yiheng Xu,
              Danyang Zhang, Apurva Gandhi, Fan Yang, Joseph Liu, Tianyue Ou,
              Zhihao Yuan, Frank F. Xu, Shuyan Zhou, Xingyao Wang, Xiang Yue,
              Tao Yu, Huan Sun, Yu Su, Graham Neubig <br />
              Arxiv Preprint (Arxiv 2025, Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2506.08140">
                <i
                  >AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open
                  Co-Scientists</i
                >
              </a>
              <br />
              Yifei Li*, Hanane Nour Moussa*, <strong>Ziru Chen</strong>, Shijie
              Chen, Botao Yu, Mingyi Xue, Benjamin Burns, Tzu-Yao Chiu, Vishal
              Dey, Zitong Lu, Chen Wei, Qianheng Zhang, Tianyu Zhang, Song Gao,
              Xuhui Huang, Xia Ning, Nesreen K. Ahmed, Ali Payani, Huan Sun (*
              equal contribution) <br />
              EMNLP 2025 (Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2410.05080"
                ><i
                  >ScienceAgentBench: Toward Rigorous Assessment of Language
                  Agents for Data-Driven Scientific Discovery
                </i></a
              >
              <a href="https://osu-nlp-group.github.io/ScienceAgentBench/"
                >[Website]</a
              >
              <br />
              <strong>Ziru Chen</strong>, Shijie Chen, Yuting Ning, Qianheng
              Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong
              Lu, Vishal Dey, Mingyi Xue, Frazier N. Baker, Benjamin Burns,
              Daniel Adu-Ampratwum, Xuhui Huang, Xia Ning, Song Gao, Yu Su, Huan
              Sun <br />
              ICLR 2025 (Long) <br />
              <strong>News Coverage:</strong>
              <a href="https://doi.org/10.1038/d41586-025-00275-0"
                >[Nature News]</a
              >
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2411.07228"
                ><i
                  >Tooling or Not Tooling? The Impact of Tools on Language
                  Agents for Chemistry Problem Solving
                </i></a
              >
              <a href="https://osu-nlp-group.github.io/ChemAgent/">[Website]</a>
              <br />
              Botao Yu, Frazier N. Baker, <strong>Ziru Chen</strong>, Garrett
              Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun <br />
              Findings of NAACL 2025 (Short)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2402.10890"
                ><i
                  >When is Tree Search Useful for LLM Planning? It Depends on
                  the Discriminator
                </i></a
              >
              <a href="https://github.com/OSU-NLP-Group/llm-planning-eval"
                >[Code & Data]</a
              >
              <a href="file/MSLD2024_LLM-Planning_Poster.pdf">[Poster]</a>
              <br />
              <strong>Ziru Chen</strong>, Michael White, Raymond Mooney, Ali
              Payani, Yu Su, Huan Sun <br />
              ACL 2024 (Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2402.08831"
                ><i
                  >eCeLLM: Generalizing Large Language Models for E-commerce
                  from Large-scale, High-quality Instruction Data
                </i></a
              >
              <a href="https://ninglab.github.io/eCeLLM/">[Website]</a>
              <br />
              Bo Peng*, Xinyi Ling*, <strong>Ziru Chen</strong>, Huan Sun, Xia
              Ning (* equal contribution) <br />
              ICML 2024 (Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2305.13683"
                ><i>Error Detection for Text-to-SQL Semantic Parsing</i></a
              >
              <a
                href="https://github.com/OSU-NLP-Group/Text2SQL-Error-Detection"
                >[Code & Data]</a
              >
              <a href="file/EMNLP2023_ED_Text2SQL_Poster.pdf">[Poster]</a>
              <br />
              Shijie Chen, <strong>Ziru Chen</strong>, Huan Sun, Yu Su <br />
              Findings of EMNLP 2023 (Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2305.14215"
                ><i
                  >Exploring Chain-of-Thought Style Prompting for Text-to-SQL</i
                ></a
              >
              <a href="file/EMNLP2023_CoT_Text2SQL_Poster.pdf">[Poster]</a>
              <br />
              Chang-Yu Tai*, <strong>Ziru Chen</strong>*, Tianshu Zhang, Xiang
              Deng, Huan Sun (* equal contribution) <br />
              EMNLP 2023 (Long)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2305.13073"
                ><i
                  >Text-to-SQL Error Correction with Language Models of Code</i
                ></a
              >
              <a href="https://github.com/OSU-NLP-Group/Auto-SQL-Correction"
                >[Code & Data]</a
              >
              <a href="file/ACL2023_Ron_SQL_Correction_Poster.pdf">[Poster]</a>
              <br />
              <strong>Ziru Chen</strong>, Shijie Chen, Michael White, Raymond
              Mooney, Ali Payani, Jayanth Srinivasa, Yu Su, Huan Sun <br />
              ACL 2023 (Short)
            </li>
          </ul>
          <ul>
            <li>
              <a href="https://arxiv.org/abs/2207.05223"
                ><i
                  >Bootstrapping a User-Centered Task-Oriented Dialogue
                  System</i
                ></a
              >
              <br />
              Shijie Chen*, <strong>Ziru Chen</strong>*, Xiang Deng, Ashley
              Lewis, Lingbo Mo, Samuel Stevens, Zhen Wang, Xiang Yue, Tianshu
              Zhang, Yu Su, Huan Sun (* equal contribution) <br />
              Alexa Prize Taskbot Challenge 2022 (Long) <br />
              <strong>News Coverage:</strong>
              <a
                href="https://www.amazon.science/alexa-prize/taskbot-challenge/2021"
                >[Amazon Science]</a
              >
              <a
                href="https://cse.osu.edu/news/2022/06/osu-tacobot-team-won-third-place-honor-inaugural-alexa-prize-taskbot-challenge"
                >[OSU CSE]</a
              >
              <a
                href="https://engineering.osu.edu/news/2022/07/buckeyes-excel-amazon-alexa-prize-taskbot-challenge"
                >[OSU CoE]</a
              >
              <a
                href="https://tdai.osu.edu/news/tdai-professors-and-team-emerge-one-top-performers-inaugural-alexa-prize-taskbot-challenge"
                >[OSU TDAI]</a
              >
            </li>
          </ul>
        </div>

        <div class="tmi">
          <br />
          <h4 id="TMI">
            <strong><i>Interesting TMI</i></strong>
          </h4>
          <i
            >* TMI is a Korean short-hand of "Too Much Information," which
            roughly refers to fun facts that could have not been shared ;)</i
          >
          <br />
          I was born on Thanksgiving that year. <br />
          I can speak Chinese, English, Japanese (JLPT N2), and some elementary
          Korean. My first name in Japanese ("shì-jō") sounds like "feet
          washing" ("shee jow") in Chinese.
          <br />
          My MBTI is
          <a href="https://www.16personalities.com/intj-personality">INTJ</a>.
          My favorite quote is “Cogito, ergo sum.” (“I think. Therefore, I am.”)
          by René Descartes. <br />
          <br /><br />
        </div>
      </div>
    </div>
  </body>
</html>
